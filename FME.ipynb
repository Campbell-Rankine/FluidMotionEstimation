{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189eee6f-b4b4-403c-85f5-fc04f629eee4",
   "metadata": {},
   "source": [
    "# Fluid Motion Estimation\n",
    "___\n",
    "\n",
    "## Goal\n",
    "\n",
    "Recreate the Network and results from the paper proposed by Aleksander Holynski et Al. at the university of washington. The paper can be found at:\n",
    "\n",
    "### Paper: https://eulerian.cs.washington.edu/animating_pictures_2020.pdf\n",
    "\n",
    "### Website: https://eulerian.cs.washington.edu/\n",
    "\n",
    "![Structure](Ims/PaperStructure.png)\n",
    "\n",
    "As we can see by the network structure provided above. We have 3 main network structures we need to implement. We need our motion estimator to estimate motion fields for the static image.\n",
    "\n",
    "We need A deep symmetric splatting network to properly sample image pixels in the motion.\n",
    "\n",
    "We need our image input and output encoder/decoder.\n",
    "\n",
    "Until this point we predict the frame at timestep t. After this we need to implement a network that can smooth the looping as they have done in the paper, This considers part of the symmetric splatting network however here we need to implement a few extra steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360d42b5-6c41-4bb2-9367-3764eb68e6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\campb\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\campb\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "#Copy paste machine learning computer vision imports.\n",
    "### - imports - ###\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "### - other data augmentation imports - ### (if needed)\n",
    "### - Imports - ###\n",
    "import math\n",
    "import numpy as np\n",
    "import sklearn as sk #general imports, initial data preprocessing/OS stuff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim #Neural network imports, multiply data etc\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn.functional as F #Neural Network used in Comp4660 at ANU\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #normalize data\n",
    "from sklearn.metrics import confusion_matrix #analysis\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91687d2-5971-4372-b39b-118bd95d2d0c",
   "metadata": {},
   "source": [
    "# Motion Estimation\n",
    "\n",
    "Source Code for each subject will be provided below, however, most likely contained in a seperate file\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae0fa86-cab8-4d6e-8198-14cfff2333ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 approaches: PyTyphoon implementation, Trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd26aac-22fc-4b3c-b52d-940c33330b7f",
   "metadata": {},
   "source": [
    "# Euler Integration\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b960f-74d5-44fc-bee1-9964a76b6e50",
   "metadata": {},
   "source": [
    "# Symmetric Splatting\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f706e9-7b9f-44d3-933e-bf118b8ec541",
   "metadata": {},
   "source": [
    "# Looping\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fc3aa-0396-4145-af15-866023c81140",
   "metadata": {},
   "source": [
    "# Train\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccefab0e-eb65-473b-9faf-29c2a3802538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
